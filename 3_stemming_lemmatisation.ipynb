{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    " ## Text normalization\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "' But her work onstage did not even begin to capture the stamina required to be in the corps. Spending a week shadowing Ms. Kretzschmar was exhausting — she gave new meaning to the idea of being on your feet all day. Twelve-hour days at the David H. Koch Theater, the company’s Lincoln Center home, were hardly unusual.'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.\n",
    "\n",
    "text = \" But her work onstage did not even begin to capture the stamina required to be in the corps.\" \\\n",
    "       \" Spending a week shadowing Ms. Kretzschmar was exhausting — she gave new meaning to the idea of\" \\\n",
    "       \" being on your feet all day. Twelve-hour days at the David H. Koch Theater,\" \\\n",
    "       \" the company’s Lincoln Center home, were hardly unusual.\"\n",
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "    Split the paragraph into sentences and examine the result."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[' But her work onstage did not even begin to capture the stamina required to be in the corps',\n ' Spending a week shadowing Ms',\n ' Kretzschmar was exhausting — she gave new meaning to the idea of being on your feet all day',\n ' Twelve-hour days at the David H',\n ' Koch Theater, the company’s Lincoln Center home, were hardly unusual',\n '']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "sentences_naive = text.split('.')\n",
    "sentences_naive"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    Use the `nltk` sentence tokenizer to split the paragraph into sentences."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "' But her work onstage did not even begin to capture the stamina required to be in the corps.'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(text)\n",
    "sentences[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    Split the first sentence into words by splitting on whitespace."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['',\n 'But',\n 'her',\n 'work',\n 'onstage',\n 'did',\n 'not',\n 'even',\n 'begin',\n 'to',\n 'capture',\n 'the',\n 'stamina',\n 'required',\n 'to',\n 'be',\n 'in',\n 'the',\n 'corps.']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "words_naive = [w for w in sentences[0].split(' ')]\n",
    "words_naive"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    Split the sentences into words by using the `nltk` `word_tokenize`. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "['But',\n 'her',\n 'work',\n 'onstage',\n 'did',\n 'not',\n 'even',\n 'begin',\n 'to',\n 'capture',\n 'the',\n 'stamina',\n 'required',\n 'to',\n 'be',\n 'in',\n 'the',\n 'corps',\n '.']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "words = [w for w in nltk.word_tokenize(sentences[0])]\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "   ## Conversion to lowcase characters\n",
    "   \n",
    "   Before analysis the texts are usually converted to lowcase characters to avoid treating\n",
    "   one and the same words as different words only because the one is written with a capital\n",
    "   case characters.\n",
    "   \n",
    "   Note however that this transformation is lossy and can remove relevant information\n",
    "   from the text, e.g. \"White House\" usually refers to something quite different from a \"white house\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "['but',\n 'her',\n 'work',\n 'onstage',\n 'did',\n 'not',\n 'even',\n 'begin',\n 'to',\n 'capture',\n 'the',\n 'stamina',\n 'required',\n 'to',\n 'be',\n 'in',\n 'the',\n 'corps',\n '.']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 29
    }
   ],
   "source": [
    "words_lowcase = [w.lower() for w in words]\n",
    "words_lowcase"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "   ## Stop words removal\n",
    "   \n",
    "   Some words like \"the\", \"a\", etc. are very common in each text but do not \n",
    "   contribute to its meaning (stop words). Sometimes, e.g. in some text classification cases, those words contribute little\n",
    "   for discriminating between documents and can be removed to reduce the feature space. \n",
    "   \n",
    "   `nltk` provides a list with stopwords several languages. Here we use list of English\n",
    "   stopwords to remove these from the text."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "['But',\n 'work',\n 'onstage',\n 'even',\n 'begin',\n 'capture',\n 'stamina',\n 'required',\n 'corps',\n '.']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 20
    }
   ],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "filtered_sentence = [w for w in words if w not in english_stopwords]\n",
    "filtered_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Stemming\n",
    " \n",
    " It is usual that one and the same word occurs in different forms, e.g. fly, flying, etc.\n",
    " One way to reduce the different forms to a base form of the word (stem) is to remove the suffixes (ly, ing, ment, etc.) from the forms.\n",
    " \n",
    " Here we will use the Porter stemmer from `nltk`.  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "['but',\n 'her',\n 'work',\n 'onstag',\n 'did',\n 'not',\n 'even',\n 'begin',\n 'to',\n 'captur',\n 'the',\n 'stamina',\n 'requir',\n 'to',\n 'be',\n 'in',\n 'the',\n 'corp',\n '.']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 26
    }
   ],
   "source": [
    "stemmer = nltk.SnowballStemmer('english')\n",
    "\n",
    "stemmed_words = [stemmer.stem(w) for w in words]\n",
    "stemmed_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "  ## Lemmatization\n",
    "  \n",
    "  While stemming is useful to reduce the different forms of the word to a single form\n",
    "  it has the disadvantage that it produces invalid words like 'captur', 'requir' in the\n",
    "  example above.\n",
    "  \n",
    "  Lemmatisation provides a solution to this problem by finding the prime form (or lemma)\n",
    "   of the words. \n",
    "\n",
    "    We will use the WordNetLemmatizer provided by `nltk` to lemmatise the words\n",
    "    from the first sentence. Notice the different result for 'onstage' and 'capture'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "['But',\n 'her',\n 'work',\n 'onstage',\n 'did',\n 'not',\n 'even',\n 'begin',\n 'to',\n 'capture',\n 'the',\n 'stamen',\n 'required',\n 'to',\n 'be',\n 'in',\n 'the',\n 'corp',\n '.']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 28
    }
   ],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "lemmatized_words = [lemmatizer.lemmatize(w) for w in words]\n",
    "lemmatized_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## Part of speech tagging\n",
    " \n",
    " Part of speech (POS) tagging refers to determining the role of each word within a sentence, e.g.: \n",
    "    2.  CD  Cardinal number\n",
    "    3.  DT  Determiner    \n",
    "    4.  JJ  Adjective\n",
    "    8.  JJR Adjective, comparative\n",
    "    11. MD  Modal\n",
    "    12. NN  Noun, singular or mass\n",
    "    13. NNS Noun, plural\n",
    "    20. RB  Adverb\n",
    "    21. RBR Adverb, comparative\n",
    "    22. RBS Adverb, superlative\n",
    "    27. VB  Verb, base form\n",
    "    34. WP  Wh-pronoun\n",
    "    35. WP$ Possessive wh-pronoun\n",
    "    \n",
    "   for the full list of Penn Treebank POS tags see their [web site](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html). \n",
    "   \n",
    "   Here we use the default POS tagger from `nltk`.  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "[('But', 'CC'),\n ('her', 'PRP$'),\n ('work', 'NN'),\n ('onstage', 'NN'),\n ('did', 'VBD'),\n ('not', 'RB'),\n ('even', 'RB'),\n ('begin', 'VB'),\n ('to', 'TO'),\n ('capture', 'VB'),\n ('the', 'DT'),\n ('stamina', 'NN'),\n ('required', 'VBN'),\n ('to', 'TO'),\n ('be', 'VB'),\n ('in', 'IN'),\n ('the', 'DT'),\n ('corps', 'NN'),\n ('.', '.')]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 33
    }
   ],
   "source": [
    "tagged_words = nltk.pos_tag(words)\n",
    "tagged_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## Ambiguities with lemmatisation \n",
    " \n",
    " Look at the following sentence: \"Visiting aunts can be quite annoying\" and examine\n",
    " the POS tags generated by `nltk.pos_tag`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Visiting', 'VBG'),\n ('aunts', 'NNS'),\n ('can', 'MD'),\n ('be', 'VB'),\n ('quite', 'RB'),\n ('annoying', 'VBG')]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 34
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(\"Visiting aunts can be quite annoying\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}